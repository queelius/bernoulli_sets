%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Many computational systems rely on \emph{approximate set representations}---data structures whose membership queries may err, returning false positives or false negatives with known rates.
Bloom filters~\cite{bf}, perfect hash filters~\cite{phf}, and related probabilistic data structures achieve dramatic space savings by tolerating such errors, and individual structures are well understood.
However, practical systems rarely use a single approximate set in isolation.
Encrypted search indexes, database query planners, and distributed systems routinely compose approximate sets through union, intersection, complement, and difference, and the resulting error behavior has traditionally been analyzed on a case-by-case basis.

\paragraph{The gap.}
The existing literature lacks a \emph{compositional algebra} for approximate sets: a framework in which the error rates of any set-theoretic expression are mechanically computable from the error rates of its operands.
Without such a framework, each new combination of approximate sets requires a bespoke analysis, and higher-order compositions---approximate sets of approximate sets---remain largely uncharacterized.

\paragraph{Contribution.}
We introduce the \emph{Bernoulli set model}, a probabilistic framework for \emph{random approximate sets} built on two axioms: element-wise independence of errors and conditional independence of block error rates.
From these axioms we derive:
\begin{enumerate}[nosep]
    \item the binomial distributions of error counts (false positives, false negatives, true positives, true negatives) and their asymptotic normal limits,
    \item the higher-order composition theorem: the $k$-fold composition of approximate identity functions yields a Bernoulli set whose rates are given by the product of binary channel transition matrices, and
    \item confidence intervals for the realized false positive and true positive rates.
\end{enumerate}
The framework is formulated as an abstract data type: any implementation whose membership queries satisfy the Bernoulli axioms---including Bloom filters, perfect hash filters, and their compositions---inherits the full theory automatically.

\paragraph{Related work.}
The original Bloom filter~\cite{bf} introduced approximate set membership with one-sided error.
Subsequent work has produced a rich family of probabilistic data structures---including cuckoo filters~\cite{cuckooFilter}, quotient filters~\cite{quotientFilter}, xor filters~\cite{xorFilter}, and ribbon filters~\cite{ribbonFilter}---surveyed by Broder and Mitzenmacher~\cite{broderMitzenmacher}, with improved space efficiency or additional functionality.
Bose et al.~\cite{boseBloom} give tight bounds on the Bloom filter false positive rate, Kirsch and Mitzenmacher~\cite{kirschMitzenmacher} show that two hash functions suffice, and Carter and Wegman~\cite{carterWegman} provide the universal hash families underlying many implementations.
Related probabilistic summaries such as the count-min sketch~\cite{countMinSketch} trade exact answers for space efficiency in the streaming setting.
However, analyses typically treat each structure in isolation, deriving error rates for a single filter rather than for compositions of filters.
General probabilistic methods for randomized algorithms~\cite{mitzenmacherUpfal} provide the analytical toolkit (concentration inequalities, entropy bounds) but do not address the compositional structure of approximate sets.
Our framework complements these lines of work by providing an algebraic layer that sits above any particular implementation; the interval arithmetic extension for uncertain rate parameters is developed in~\cite{bernoulliComposition}.

\paragraph{Companion papers.}
The set-theoretic composition of Bernoulli sets---closed-form error rates for complement, union, intersection, and set difference, monoidal structure, relational predicates, and interval arithmetic---is developed in a companion paper~\cite{bernoulliComposition}.
The probability distributions of binary classification measures (precision, recall, accuracy, etc.) induced by the Bernoulli model are derived in~\cite{bernoulliMeasures}.
The joint entropy of error counts and the information-theoretic space complexity of approximate sets are developed in~\cite{bernoulliEntropy}.

\paragraph{Organization.}
\Cref{sec:setalgebra} reviews the algebra of sets.
\Cref{sec:bernoulli_model} introduces the Bernoulli set model and its axioms, including the higher-order composition theorem.
\Cref{sec:characteristics} derives the binomial distributions of error counts and their asymptotic normal limits.

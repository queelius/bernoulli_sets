%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Distributions of error counts
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distributions of error counts}
\label{sec:characteristics}
The error rate on some identically distributed subset is an \emph{expectation}.
However, some \emph{error measures} span multiple subsets, such as positives and negatives.
Any such error measure may be modeled as a \emph{Bernoulli mixture}.

We are typically interested in the error rates of \emph{special} subsets.
For example, if we have a universal set $\Set{X}$ and with probability $P(x)$ an element $x \in \Set{X}$ is tested for membership in a collection of sets over $\Set{X}$, then to reduce the expected error rate on membership tests elements with higher probability of being tested should be assigned smaller error rates.


The second-order random approximate sets are \emph{parameterized} by the \emph{expected} rates of two types of error, false negative and false positive rates.
In this section, we derive the distribution for these rates.

\begin{definition}
The uncertain number of \emph{negatives} is a random variable denoted by $\RV{N}$ and is statistically dependent on $R$,
\begin{equation}
\RV{N} = |\RV{R}^c|,
\end{equation}
\end{definition}

\begin{definition}
The uncertain number of false positives is a random variable denoted by $\FP$ and is statistically dependent on $\RV{N}$ and $\alpha$,
\begin{equation}
	\FP = \RV{N} \alpha.
\end{equation}
\end{definition}

The number of false positives given a specific number of negatives is given by the following theorem.
\begin{theorem}
\label{thm:fpbinom}
The random number of false positives $\FP$ given $\RV{N} = n$ in the second-order random approximate set $\tilde{\RV{R}}[\fprate]$ is given by
\begin{equation}
	\FP_n = n \alpha
\end{equation}
with a distribution given by
\begin{equation}
    \FP_n \sim \bindist(n, \fprate).
\end{equation}
\end{theorem}
\begin{proof}
By \cref{prop:element_rates}, the uncertain outcome that a negative element \emph{tests} as positive is a Bernoulli trial with a mean $\fprate$.
Since there are $n$ such independent and identically distributed trials, the number of false positives is binomially distributed with a mean $n \fprate$.
\end{proof}

The false positive rate $\fprate$ is an \emph{expectation}.
However, the false positive rate of a realization of a random approximate set $\tilde{S}[\fprate]$ is \emph{uncertain}.
\begin{theorem}
\label{thm:fpr}
The random false positive rate $\alpha$ conditioned on $\RV{N} = n$ is denoted by $\alpha_n$ and has a distribution given by
\begin{equation}
    \alpha_n = \frac{\FP_n}{n},
\end{equation}
with an expectation $\fprate$, variance $\fprate(1-\fprate) / n$, and probability mass function
\begin{equation}
	p_{\alpha_n}(\fprateob | \fprate) = p_{\FP_n}(\fprateob n | \fprate)
\end{equation}
over the support $\SetBuilder{ \frac{j}{n} \in \RatSet}{j \in \{0,\ldots,n\}}$.
\end{theorem}
\begin{proof}
By \cref{def:fprate}, the false positive rate is given by the ratio of the number of false positives to the total number of negatives.
By \cref{thm:fpbinom}, given that there are $n$ negatives, the number of false positives is a random variable denoted by $\FP_n$.
Therefore, the false positive rate, as a function of $\FP_n$, is the random variable $\frac{\FP_n}{n}$.
The \emph{expected} false positive rate is
\begin{equation}
    \Expect{\frac{\FP_n}{n}} = \frac{1}{n}\Expect{\FP_n} = \fprate
\end{equation}
and its variance is
\begin{equation}
    \Var{\frac{\FP_n}{n}} = \frac{1}{n^2}\Var{\FP_n} = \frac{\fprate(1-\fprate)}{n}.
\end{equation}
Finally, $\alpha_n = \FP_n / n$ is a \emph{scaled} transformation of the binomial distribution.
Thus, since $\FP_n = n \alpha_n$,
\begin{equation}
	p_{\alpha_n}(\fprateob_n | \fprate) = p_{\FP_n}(n \fprateob).
\end{equation}
\end{proof}
The following corollary immediately follows.
\begin{corollary}
	\label{cor:tnbinom}
	Given $n$ negatives, the number of \emph{true negatives} in a random approximate set with a false positive rate $\fprate$ is a random variable denoted by $\TN_n$ with a distribution given by
	\begin{equation}
	\TN_n = n - \FP_n \sim \bindist\!\left(n, 1-\fprate\right).
	\end{equation}
	By definition, the \emph{true negative rate} $\mathrm{TNR}_n = \TN_n / n = 1 - \alpha_n$.
\end{corollary}

By \cref{thm:fpr}, the more negatives there are, the lower the variance.
\begin{corollary}
\label{cor:fpr_as_vareps}
	Given \emph{countably infinite} negatives, a random approximate set with a false positive rate $\fprate$ is \emph{certain} to obtain $\fprate$.
\end{corollary}
\begin{proof}
We know that the \emph{expected} value for each of the random variables in this sequence is $\fprate$ and the variance is $\fprate(1-\fprate)/n$.
Immediately, we see that as $n$ increases, the distribution of false positives must become more concentrated around $\fprate$.
As $n \to \infty$, the variance goes to $0$, i.e., the distribution becomes degenerate with all of the probability mass assigned to the mean. See \cref{app:cor_fpr_as_vareps} for a more rigorous proof.
\end{proof}

The fewer negatives, the greater the variance.
The maximum possible variance, when $n=1$ and $\fprate = 0.5$, is $0.25$, may be used as the most \emph{pessimistic} estimate given a situation where we have no information about the false positive rate $\fprate$ and the cardinality of the universal set.

A degenerate case is given by letting $n = 0$, corresponding to a random approximate set of the universal set which has no negative elements that can be tested.
Respectively, only random \emph{negative} or \emph{positive} approximate sets may be generated for the universal set or empty set.

The number of false negatives is given by the following theorem.
\begin{theorem}
\label{thm:fnbinom}
Given $p$ positives, the uncertain number of \emph{false negatives} in random approximate sets with a false negative rate $\fnrate$ is modeled as a binomial distributed random variable denoted by $\FN_p$,
\begin{equation}
	\FN_p \sim \bindist(p, \fnrate).
\end{equation}
\end{theorem}
\begin{proof}
By \cref{prop:element_rates}, the probability that a positive element \emph{tests} as negative is $\fnrate$.
Thus, each test is a Bernoulli trial.
Since there are $p = \Card{\Set{S}}$ such independent and identically distributed trials with a probability of ``success'' $\fnrate$, the number of false negatives is binomially distributed.
\end{proof}

The false negative rate $\fnrate$ is an \emph{expectation}.
However, the false negative rate of an approximate set $\tilde{S}$ parameterized by $\fnrate$ is \emph{uncertain}.
\begin{theorem}
\label{thm:fnr}
The false negative rate realizes an uncertain value as given by
\begin{equation}
    \beta_p = \frac{\FN_p}{p}
\end{equation}
with a support $\SetBuilder{j / p}{j = 0,\ldots,p}$, an expectation
$\fnrate$, and a variance $\fnrate(1-\fnrate) / p$.
\end{theorem}
The proof follows the same logic as the proof for \cref{thm:fpr}, with $\FN_p \sim \bindist(p, \fnrate)$ in place of $\FP_n \sim \bindist(n, \fprate)$.

In the companion paper~\cite{bernoulliComposition}, we consider set-theoretic
operations like \emph{complements}. The \emph{complement} operator applied to an
approximate set of a set with countably infinite negatives is an approximate set
of a set with countably infinite positives.
\begin{corollary}
An approximate set of a set with countably infinite positives has a false
negative rate that is \emph{certain} to obtain $\fnrate$.
\end{corollary}
The proof follows the same logic as the proof for \cref{cor:fpr_as_vareps}, replacing negatives with positives and $\fprate$ with $\fnrate$.

The number of true positives is given by the following corollary.
\begin{corollary}
\label{cor:tpbinom}
Given $p$ positives, the number of \emph{true positives} in an approximate set
with a false negative rate $\fnrate$ is a random variable denoted by $\TP_p$
with a distribution given by
\begin{equation}
    \TP_p \sim \bindist(p, \tprate).
\end{equation}
By definition, the \emph{true positive rate} is given by $\TPR_p = 1 -
\beta_p$.
\end{corollary}
The proof follows the same logic as the proof for \cref{thm:fpr}, with $\TP_p = p - \FN_p$ and $\tprate = 1 - \fnrate$.

Many other properties of random approximate sets follow from these distributions.
For instance, the distribution of $\Card{\tilde{A}^\fprate_\tprate}$ given $p$ positives is
\begin{equation}
	\Card{\tilde{A}^\fprate_\tprate} = \TP_p + \FP_{u - p}
\end{equation}
where $u$ is the cardinality of the universal set. This sum has an expectation of $(u - p) \fprate + p \tprate$ and variance of $(u - p) \fprate(1-\fprate) + p \tprate(1-\tprate)$, which is the generalization of the binomial distribution known as the \emph{Poisson binomial distribution}.

If we do not know the number of positives $p$, the cardinality $\Set{A}$, but have observed $\tilde{A}^\fprate_\tprate = \Set{B}$, then $\Set{B}$ has a cardinality that tends to be centered around $u \fprate + p (\tprate - \fprate)$.
Solving for $p$ yields a method of moments estimator
\begin{equation}
	\widehat{p} = \frac{|\Set{B}| - u \fprate}{\tprate - \fprate}.
\end{equation}
If the universal set $U$ is infinite, then this estimator is undefined.

\subsection{Asymptotic limits}
\label{sec:asymtotic}
The false positive and false negative rates are a function of the cardinality of the objective and universal sets.
The limiting distributions for the false positive and true positive rates are given by the following theorems.
\begin{theorem}
    \label{thm:approxfpr}
    By \cref{thm:fpr}, the uncertain false positive rate $\alpha_n$ converges in
    distribution to the normal distribution with a mean $\fprate$ and a
    variance $\fprate(1-\fprate)/n$, written
    \begin{equation}
    \label{eq:approxfpr}
	    \alpha_n \xrightarrow{d} \normdist(\fprate, \fprate(1-\fprate) / n).
    \end{equation}
    Similarly, by \cref{cor:tpbinom}, the uncertain true positive rate of an approximate  set of $p$ positives, denoted by $\TPR_p$, converges in distribution to the normal distribution with a mean $\tprate$ and a variance $\tprate(1-\tprate)/p$, written
    \begin{equation}
    \label{eq:approxtpr}
    	\TPR_p \xrightarrow{d} \normdist(\tprate, \tprate(1-\tprate) / p).
    \end{equation}
\end{theorem}
\begin{proof}
    By \cref{thm:fpr}, given $n$ negatives, the false positive rate is
    \begin{equation}
    	\alpha_n = \frac{\RV{X_1}}{n} + \cdots + \frac{\RV{X_n}}{n},
    \end{equation}
    where $\RV{X_1},\ldots,\RV{X_n}$ are $n$ independent Bernoulli trials each with a mean $\fprate$ and a variance $\fprate(1-\fprate)$.
    Therefore, by the central limit theorem~\cite{feller2}, $\alpha_n$ converges in distribution to a normal distribution with a mean $\fprate$  and a variance $\fprate(1-\fprate)/n$.
    The proof for the true positive rate follows the same logic, replacing $\fprate$ with $\tprate$, $n$ with $p$, and negatives with positives.
\end{proof}
By \cref{eq:approxfpr,eq:approxtpr},
\begin{equation}
	\mathrm{TNR}_n \xrightarrow{d} \normdist\!\left(1-\fprate, \fprate(1-\fprate) / n\right) \text{ and } \beta_p \xrightarrow{d} \normdist\!\left(1-\tprate, \tprate(1-\tprate) / p\right).
\end{equation}

The Bernoulli set model is the \emph{maximum entropy} distribution over $\{0,1\}^u$ subject to the constraint that each element has a fixed marginal error probability: the binomial distribution maximizes entropy over $\{0,\ldots,n\}$ for a given mean~\cite{coverThomas}.
As a consequence, any $\gamma$-confidence intervals derived from this model are the widest possible for the indicated $\gamma$ and therefore represent a worst-case uncertainty.

If we generate an approximate set, the uncertain false positive and true positive rates realize certain values, i.e., $\alpha_n = \fprateob$ and $\TPR_p = \tprateob$.
If the sample space is countably infinite, the distribution is degenerate, e.g., $\alpha_n = \fprate$ with probability $1$.
However, for finite sample spaces, the outcomes are uncertain.
If these outcomes can be \emph{observed}, e.g., it is not too costly to compute, the exact values $\fprateob$ and $\tprateob$ may be recorded.
If these outcomes cannot be observed, e.g., it is too costly to compute or the information to compute $\fprateob$ or $\tprateob$ is not available, we may use the probabilistic model to inform us about the distribution of false positive rates.

\emph{Confidence intervals} that contain the true false positive rate $\fprateob$ and the true true positive rate $\tprateob$ are given by the following theorem.
\begin{theorem}
    Given a random approximate set parameterized by $\fprate$ and $\tprate$, asymptotic $\gamma \cdot 100\%$ confidence intervals for the false positive rate and true positive rate are respectively
    \begin{equation}
    \label{eq:conf_fpr}
    \fprate \pm \sqrt{\frac{\fprate(1-\fprate)}{n}} \Phi^{-1}\!\left(\frac{1+\gamma}{2}\right)
    \end{equation}
    and
    \begin{equation}
    \label{eq:conf_tpr}
    \tprate \pm \sqrt{\frac{\tprate(1-\tprate)}{p}} \Phi^{-1}\!\left(\frac{1+\gamma}{2}\right),
    \end{equation}
    where $\Phi^{-1} : [0,1] \to \RealSet$ is the inverse cumulative distribution function of the standard normal.
\end{theorem}
\begin{proof}
By \cref{thm:approxfpr}, $\alpha_n$ is asymptotically normal with mean $\fprate$ and variance $\sigma^2 = \fprate(1-\fprate)/n$.
Standardizing, $Z = (\alpha_n - \fprate)/\sigma \xrightarrow{d} \normdist(0,1)$.
A $\gamma$-level confidence interval requires
$\Prob{-z_\gamma \leq Z \leq z_\gamma} = \gamma$,
where $z_\gamma = \Phi^{-1}\!\left(\frac{1+\gamma}{2}\right)$.
Substituting and solving for $\alpha_n$ yields
$\fprate \pm \sigma \, z_\gamma = \fprate \pm \sqrt{\fprate(1-\fprate)/n}\;\Phi^{-1}\!\left(\frac{1+\gamma}{2}\right)$.
The argument for the true positive rate is identical with $\tprate$ and $p$ replacing $\fprate$ and $n$.
\end{proof}
As a worst-case (maximum uncertainty), we may let $n = p = 1$ in \cref{eq:conf_fpr,eq:conf_tpr}.
%However, if the universe is large and the objective sets are relatively small, a slightly optimistic confidence interval for $\fprate$ is provided by letting $n = \Card{\Set{U}}$.
